{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyObH1tJtSlOUm4NRg+Zw1a2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Métodos para importar datasets con Pandas"
      ],
      "metadata": {
        "id": "AtJpnsxspqt4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Links que vamos a usar:"
      ],
      "metadata": {
        "id": "SQPoi9uIfUJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* [Blog Kaggle - International Hotel Booking Analytics](https://www.kaggle.com/code/sonawanelalitsunil/international-hotel-booking-analytics-ml-34-75/notebook)\n",
        "* [Datasets Kaggle - International Hotel Booking Analytics](https://www.kaggle.com/datasets/alperenmyung/international-hotel-booking-analytics)\n",
        "* [Dataset Github - LifeExpectancy ](https://raw.githubusercontent.com/resbaz/r-novice-gapminder-files/master/data/gapminder-FiveYearData.csv)\n",
        "* [Dataset Kaggle - Netflix](https://www.kaggle.com/datasets/shivamb/netflix-shows/code)"
      ],
      "metadata": {
        "id": "5CDwBA2tpt23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Descargar los datasets (archivos .csv) antes de comenzar"
      ],
      "metadata": {
        "id": "z8RTgLrAwjy3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Opción 1:\n",
        "Decargarlos desde el Repositorio Oficial del Curso [Click Aquí](https://drive.google.com/drive/folders/1LI3HcSqcrSJ52YZAoQG0NNmdOnHVSJHG)\n",
        "* Opción 2:\n",
        "Decargarlos desde Kaggle [Click Aquí](https://www.kaggle.com/datasets/alperenmyung/international-hotel-booking-analytics) - Haciendo click en el botón Download/Descargar (Debe descomprimir el archivo \"archive.zip\")"
      ],
      "metadata": {
        "id": "-wNMH1OGhWBl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Preparar los archivos en Google Drive"
      ],
      "metadata": {
        "id": "kj6GV85devHf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Crear en su unidad de Google Drive la carpeta \"datasets\"\n",
        "2. Subir a esa carpeta los archivos:\n",
        "* hotels.csv\n",
        "* reviews.csv\n",
        "* users.csv"
      ],
      "metadata": {
        "id": "bHoI91tiiyqX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Montar y liberar la unidad"
      ],
      "metadata": {
        "id": "FldXXQ72929y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código permite montar la unidad de su Drive en este ambiente virtual de Colab"
      ],
      "metadata": {
        "id": "mkFHp34GjGgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Montar la unidad\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ALDG9MtAz268"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al finalizar la actividad o en caso que lo requiera, puede desmontar la unidad con este código"
      ],
      "metadata": {
        "id": "7FrKv6kojR4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Liberar la unidad\n",
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "5ZhjulY-8wb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Importar datasets"
      ],
      "metadata": {
        "id": "-Gr5xwCMjjCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación veremos varias opciones para importar datasets a Google Colab usando Pandas, el método dependerá de la necesidad y de sus conocimientos, por ello se plantean varios escenarios para cada nivel."
      ],
      "metadata": {
        "id": "27BIEobVjmNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Importar datasets desde Google Sheets  (Nivel Inicial)"
      ],
      "metadata": {
        "id": "vWgQoVMd0hVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar la librería Pandas\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "M_2t2dgOkFdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Acceso a Gsheets - Metodo con URL de conversion a CSV (lectura)\n",
        "# El archivo debe tener permisos de lectura para TODOS\n",
        "ID_planilla = '1LeWVQ0Pd9XlQ70oTWggueRGLBXISMTGDiLG7wZ6otSI'\n",
        "URL = f'https://docs.google.com/spreadsheets/d/{ID_planilla}/gviz/tq?tqx=out:csv&sheet='\n",
        "df_gs = pd.read_csv(URL + 'ventas')\n",
        "df_gs.head()"
      ],
      "metadata": {
        "id": "BPWfIZPf0iDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Importar datasets desde Google Drive  (Nivel Inicial)\n"
      ],
      "metadata": {
        "id": "QlUQhrm2yces"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta instancia, ya deberías tener creada la carpeta `datasets` en el raíz de tu Unidad de Google Drive, y ahi haber subido los archivos csv que vamos a usar"
      ],
      "metadata": {
        "id": "pAweq7H_QL5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar que los archivos csv se encuentren en la carpeta datasets\n",
        "import os\n",
        "os.listdir(\"/content/drive/MyDrive/datasets\")"
      ],
      "metadata": {
        "id": "KHgehMBJQGx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar la librería Pandas\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "9tdTFMOFSd0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usar el método read_csv de Pandas (pd) que recibe como argumento el archivo csv y retorna un dataframe\n",
        "df_users = pd.read_csv('/content/drive/MyDrive/datasets/users.csv')\n",
        "df_users.head()"
      ],
      "metadata": {
        "id": "mp6tO9sqQk1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 Importar datasets desde Google Drive (Nivel Intermedio)"
      ],
      "metadata": {
        "id": "oRcDT__OQ4pI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si van a trabajar con datasets que se encuentran en diferentes carpetas, puden cambiar la ruta por defecto"
      ],
      "metadata": {
        "id": "j1BXJiltPA5f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Se sugiere usar el panel de navegación laterar para explorar las carpetas y sus archivos.\n",
        "2. Cambiar la ruta original al directorio donde se encuentran los archivos .csv que se quieren importar"
      ],
      "metadata": {
        "id": "Z8MPOaF8-LdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validar la ruta y la existencia del archivo csv a importar\n",
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/TT2C2025 - Data Analytics con Python/Repositorio Notebooks de clases/Clase 3/Datasets\")\n",
        "os.listdir(\".\")"
      ],
      "metadata": {
        "id": "2iYzc0hM16_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar la librería Pandas\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "xOSUn5XEUz4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usar el método read_csv de Pandas (pd) que recibe como argumento el archivo csv y retorna un dataframe\n",
        "df = pd.read_csv('users.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Q7hYj8kd0HaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4 Importar datasets desde Github"
      ],
      "metadata": {
        "id": "HNxpXDs_4ESy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar en una variable la URL del archivo csv de Github\n",
        "url = \"https://raw.githubusercontent.com/resbaz/r-novice-gapminder-files/master/data/gapminder-FiveYearData.csv\""
      ],
      "metadata": {
        "id": "gceBkvvkU9U2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar la librería Pandas\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "CeJUej9D4R6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usar el método read_csv de Pandas (pd) que recibe como argumento el archivo csv y retorna un dataframe\n",
        "df_github = pd.read_csv(url)\n",
        "df_github.head()"
      ],
      "metadata": {
        "id": "jAThz1QOVGt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.5 Importar Datasets públicos desde Kaggle (Nivel Avanzado)\n",
        "\n",
        "\n",
        "> Para datasets públicos que no requieren autenticación\n",
        "\n"
      ],
      "metadata": {
        "id": "ZoP6qhipF5zu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuando quieran descargar un dataset público desde Kaggle, hacer click en download y pegrn el código \"Download Via kagglehub\"\n",
        "<BR>\n",
        "En este caso vamos a descargar el dataset [Netflix Movies](https://www.kaggle.com/datasets/shivamb/netflix-shows/code)"
      ],
      "metadata": {
        "id": "-bDUYhhMbH0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"shivamb/netflix-shows\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "dtYzg3RjMj9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kagglehub descarga sus archivos en un cache, path informa la ruta.\n",
        "<BR>\n",
        "Lo que hacemos es copiarlo a la carpeta \"datasets\" de nuestro drive"
      ],
      "metadata": {
        "id": "jZubEQ-ibGC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Montar la unidad\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zp98bNoFaS00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "# Carpeta destino\n",
        "dest_dir = \"/content/drive/MyDrive/datasets/\"\n",
        "\n",
        "# Copiar todos los archivos del dataset al destino\n",
        "for file in os.listdir(path):\n",
        "    shutil.copy(os.path.join(path, file), dest_dir)\n",
        "\n",
        "print(\"Archivos copiados a:\", dest_dir)\n",
        "print(\"Contenido:\", os.listdir(dest_dir))"
      ],
      "metadata": {
        "id": "6x9x8bzdZxdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usar el método read_csv de Pandas (pd) que recibe como argumento el archivo csv y retorna un dataframe\n",
        "df = pd.read_csv(f\"{path}/netflix_titles.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "5BiSK3f4M_5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.6 Importar Datasets privados desde Kaggle (Nivel Avanzado)\n",
        "\n",
        "\n",
        "> Para datasets privados que si requieren autenticación"
      ],
      "metadata": {
        "id": "WIA6SNeKcIcu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crear una carpeta en el raíz del Drive llamada `kaggle` y pegar el archivo `kaggle.json` (API Token) que generan desde su perfil de Kaggle"
      ],
      "metadata": {
        "id": "6dm-mx94aerh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Montar la unidad\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BR314at2F8F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validar la existencia del JSON\n",
        "import os\n",
        "os.listdir(\"/content/drive/MyDrive/kaggle\")"
      ],
      "metadata": {
        "id": "QDu-IQntIRrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código crear una carpeta kaggle en el raíz y la segunda linea un copy/paste de `kaggle.json`"
      ],
      "metadata": {
        "id": "tTMW5jC_cgv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/drive/MyDrive/kaggle/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "3lDWa_cxHepx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso vamos a descargar el mismo dataset [Netflix Movies](https://www.kaggle.com/datasets/shivamb/netflix-shows/code)\n",
        "<BR>\n",
        "Aunque al ser público esto no es necesario\n"
      ],
      "metadata": {
        "id": "xc2jTvBGckic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Este código descarga el dataset con las credenciales\n",
        "!kaggle datasets download -d shivamb/netflix-shows -p /content/drive/MyDrive/datasets\n",
        "!unzip /content/drive/MyDrive/datasets/netflix-shows.zip -d /content/drive/MyDrive/datasets"
      ],
      "metadata": {
        "id": "y5qW5xY7Hvqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validar la existencia del archivo descargado\n",
        "import os\n",
        "os.listdir(\"/content/drive/MyDrive/datasets\")"
      ],
      "metadata": {
        "id": "TBcs2fWCdU67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar la librería Pandas\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Jw5mjWQ2WwYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/datasets/netflix_titles.csv\")\n",
        "print(df.shape)   # filas y columnas\n",
        "df.head()         # primeras 5 filas"
      ],
      "metadata": {
        "id": "RH4MLEIUa0EH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.7 Importar Datos desde una base de datos relacional ya subida a la carpeta datasets del raíz\n"
      ],
      "metadata": {
        "id": "6YfoTeOd5Uc3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta modalidad, deben descargar la carpeta zip desde desde este link\n",
        "<BR>\n",
        "[Descargar](https://www.kaggle.com/datasets/alperenmyung/international-hotel-booking-analytics)\n",
        "<BR>\n",
        "Descomprimir la carpeta y subir el archivo `booking_db.sqlite` a la carpeta `/datasets` de su Drive"
      ],
      "metadata": {
        "id": "_xfHexMA6rR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Montar la unidad\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vF5wF_IV5emO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validar la existencia de la DB\n",
        "import os\n",
        "os.listdir(\"/content/drive/MyDrive/datasets\")"
      ],
      "metadata": {
        "id": "vrhgOxBr5hrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos las librerías\n",
        "import sqlite3\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "cA8b0ImV5n2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Establecemos la conexión a la db\n",
        "conexion = sqlite3.connect('/content/drive/MyDrive/datasets/booking_db.sqlite')"
      ],
      "metadata": {
        "id": "lgj6yIeh5rNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_sql('''\n",
        "    SELECT\n",
        "        *\n",
        "    FROM reviews\n",
        "    ;\n",
        "''', conexion, index_col='review_id', parse_dates=['review_date'])"
      ],
      "metadata": {
        "id": "8UPDdkkh5x_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_sql('''\n",
        "    SELECT\n",
        "    review_id, hotel_name, city, star_rating, score_overall, u.country\n",
        "    FROM hotels h\n",
        "    join reviews r on h.hotel_id = r.hotel_id\n",
        "    join users u on r.user_id = u.user_id\n",
        "    order by score_overall asc\n",
        "    ;\n",
        "''', conexion, index_col='review_id')"
      ],
      "metadata": {
        "id": "UFAio6cf50ZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_sql('''\n",
        "    SELECT\n",
        "    review_id, hotel_name, city, avg(score_overall)\n",
        "    FROM hotels h\n",
        "    join reviews r on h.hotel_id = r.hotel_id\n",
        "    group by hotel_name, city\n",
        "    order by avg(score_overall) desc\n",
        "    ;\n",
        "''', conexion, index_col='review_id')"
      ],
      "metadata": {
        "id": "opL36JfF52go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.8 Importar Datos desde una base de datos relacional (usando credenciales de Kaggle - descarga directa)"
      ],
      "metadata": {
        "id": "erUET5-eAtCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Montar la unidad\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JfS3D0FVGJee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validar la existencia del JSON\n",
        "import os\n",
        "os.listdir(\"/content/drive/MyDrive/kaggle\")"
      ],
      "metadata": {
        "id": "uOrBzDC_GKFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos una carpeta temporal en el ambiente virtual\n",
        "!mkdir -p ~/.kaggle\n",
        "# ahí pegamos las credenciales\n",
        "!cp /content/drive/MyDrive/kaggle/kaggle.json ~/.kaggle/\n",
        "# cambiamos los permisos\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "sduvcr-6G-fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Este código descarga el dataset con las credenciales a la carpeta datasets\n",
        "!kaggle datasets download -d alperenmyung/international-hotel-booking-analytics -p /content/drive/MyDrive/datasets\n",
        "# y con esta línea hacemos el unzip\n",
        "!unzip /content/drive/MyDrive/datasets/international-hotel-booking-analytics.zip -d /content/drive/MyDrive/datasets"
      ],
      "metadata": {
        "id": "-MMj-YXiHEKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos las librerías\n",
        "import sqlite3\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "OZiq-AT9IInQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Establecemos la conexión a la db\n",
        "conexion = sqlite3.connect('/content/drive/MyDrive/datasets/booking_db.sqlite')"
      ],
      "metadata": {
        "id": "ANsHSHCtIR47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_sql('''\n",
        "    SELECT\n",
        "        *\n",
        "    FROM reviews\n",
        "    ;\n",
        "''', conexion, index_col='review_id', parse_dates=['review_date'])"
      ],
      "metadata": {
        "id": "0m19EvEOA0pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_sql('''\n",
        "    SELECT\n",
        "    review_id, hotel_name, city, star_rating, score_overall, u.country\n",
        "    FROM hotels h\n",
        "    join reviews r on h.hotel_id = r.hotel_id\n",
        "    join users u on r.user_id = u.user_id\n",
        "    order by score_overall asc\n",
        "    ;\n",
        "''', conn, index_col='review_id')"
      ],
      "metadata": {
        "id": "qUdYvhlQJ75s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_sql('''\n",
        "    SELECT\n",
        "    review_id, hotel_name, city, avg(score_overall)\n",
        "    FROM hotels h\n",
        "    join reviews r on h.hotel_id = r.hotel_id\n",
        "    group by hotel_name, city\n",
        "    order by avg(score_overall) desc\n",
        "    ;\n",
        "''', conn, index_col='review_id')"
      ],
      "metadata": {
        "id": "RsJMixXATyXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "TbTrLmfo6Z6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "FnzMjnFC6bk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "qUwjXGZN6gmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "jl2Qnw4qI1fS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}